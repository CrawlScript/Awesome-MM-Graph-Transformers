# Awesome Multimodal Graph Transformers

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

A curated list of Graph Transformers (Single & Multi-modal) â€” covering both Traditional Architectures and LLM-based Graph Learning (ğŸ“ Legend: ğŸ•¸ï¸ Single-Modal, ğŸŒˆ Multi-Modal).



## Traditional Graph Transformers

- ğŸŒˆ **NTSFormer: A Self-Teaching Graph Transformer for Multimodal Isolated Cold-Start Node Classification** (AAAI 2026) - Hu, et al. [[Paper]](https://arxiv.org/abs/2507.04870) [[Code]](https://github.com/CrawlScript/NTSFormer)
- ğŸŒˆ **Multimodal Graph Transformer for Multimodal Question Answering** (EACL 2023) - He, et al. [[Paper]](https://aclanthology.org/2023.eacl-main.15/)

  
- ğŸ•¸ï¸ **HINormer: Representation Learning On Heterogeneous Information Networks with Graph Transformer** (WWW 2023) - Mao, et al. [[Paper]](https://arxiv.org/pdf/2302.11329) [[Code]](https://github.com/Ffffffffire/HINormer)
- ğŸ•¸ï¸ `[Graphormer]`  **Do Transformers Really Perform Bad for Graph Representation?** (NeurIPS 2021) - Ying, et al. [[Paper]](https://proceedings.neurips.cc/paper/2021/hash/f1c1592588411002af340cbaedd6fc33-Abstract.html) [[Code]](https://github.com/Microsoft/Graphormer)




## LLM-based Graph Learning

- ğŸ•¸ï¸ **DGP: A Dual-Granularity Prompting Framework for Fraud Detection with Graph-Enhanced LLMs** (AAAI 2026) - Li, et al. [[Paper]](https://arxiv.org/abs/2507.21653)



